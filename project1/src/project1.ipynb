{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='pipeline.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logistic as log\n",
    "import split as spl\n",
    "import least_squares as lst\n",
    "import helpers as hlp\n",
    "import pre_processing as pre\n",
    "import vizu as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd # cannot use external libraries, just pandas for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y, tX, ids = hlp.load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = hlp.load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tX.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_TRAIN_PATH)\n",
    "test_data = pd.read_csv(DATA_TEST_PATH)\n",
    "dic = {'s':1,'b':-1}\n",
    "data.Prediction = data.Prediction.map(dic)\n",
    "test_data.Prediction = test_data.Prediction.map(dic)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.isin([-999]).any(axis = 1)\n",
    "print(len(data[mask]))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The vast majoriy of our data has -999 values: we'd better handle it carefully_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.replace(to_replace = -999,value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace_val = np.nan\n",
    "#tX = np.where(tX == -999,replace_val,tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.nanstd(tX,axis = 0)\n",
    "mean = np.nanmean(tX,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: {} samples x {} features'.format(pd.DataFrame(tX).shape[0], pd.DataFrame(tX).shape[1]))\n",
    "print('Test set size: {} samples x {} features'.format(test_data.shape[0], pd.DataFrame(tX).shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class separation - Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(data.columns)[2:]\n",
    "\n",
    "data_0 = data[data['PRI_jet_num'] == 0]\n",
    "data_1 = data[data['PRI_jet_num'] == 1]\n",
    "data_2 = data[data['PRI_jet_num'] >= 2]\n",
    "\n",
    "fig, axes = plt.subplots(30, 1, figsize=(8, 150), sharex=False)\n",
    "for idx, name in enumerate(col_names):    \n",
    "    axes[idx].hist(data_0[name], bins=50, density=True, alpha=0.3, label='class 0')\n",
    "    axes[idx].hist(data_1[name], bins=50, density=True, alpha=0.3, label='class 1')\n",
    "    axes[idx].hist(data_2[name], bins=50, density=True, alpha=0.3, label='class 2 & 3')\n",
    "    axes[idx].set_title(name)\n",
    "    axes[idx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "ax0, ax1, ax2, ax3 = axes.flatten()\n",
    "\n",
    "ax0.hist(data_0['DER_mass_transverse_met_lep'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax0.hist(data_1['DER_mass_transverse_met_lep'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax0.hist(data_2['DER_mass_transverse_met_lep'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax0.legend()\n",
    "ax0.set_xlabel('Value', fontsize=10)\n",
    "ax0.set_ylabel('Proportion', fontsize=10)\n",
    "ax0.set_title('DER_mass_transverse_met_lep', fontsize=12)\n",
    "\n",
    "ax1.hist(data_0['DER_deltar_tau_lep'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax1.hist(data_1['DER_deltar_tau_lep'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax1.hist(data_2['DER_deltar_tau_lep'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Value', fontsize=10)\n",
    "ax1.set_ylabel('Proportion', fontsize=10)\n",
    "ax1.set_title('DER_deltar_tau_lep',fontsize=12)\n",
    "\n",
    "ax2.hist(data_0['DER_sum_pt'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax2.hist(data_1['DER_sum_pt'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax2.hist(data_2['DER_sum_pt'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Value', fontsize=10)\n",
    "ax2.set_ylabel('Proportion', fontsize=10)\n",
    "ax2.set_title('DER_sum_pt', fontsize=12)\n",
    "\n",
    "\n",
    "ax3.hist(data_0['PRI_met_sumet'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax3.hist(data_1['PRI_met_sumet'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax3.hist(data_2['PRI_met_sumet'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax3.legend()\n",
    "#ax3.ticklabel_format(useMathText=True)\n",
    "#ax3.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2e'))\n",
    "ax3.set_xlabel('Value', fontsize=10)\n",
    "ax3.set_ylabel('Proportion', fontsize=10)\n",
    "ax3.set_title('PRI_met_sumet', fontsize=12)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save figure\n",
    "fig.savefig(\"classes_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totrash before submit: we use pandas to know to which index PRI_jet_num does correspond.\n",
    "np.where(data.columns.values == \"PRI_jet_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trains = spl.split_categorical_data(tX,22,labels = y,split = True)\n",
    "data_tests = spl.split_categorical_data(tX_test,22,split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "stdev = 0\n",
    "clean_data_trains = []\n",
    "clean_data_tests = []\n",
    "degre_polys = [12,12,13]\n",
    "for i,((x_train,y_train),(x_test,test_indx)) in enumerate(zip(data_trains,data_tests)):\n",
    "    x_train,x_test = pre.clean_variance(x_train,x_test)\n",
    "    \n",
    "    x_train = pre.clean_value(x_train,-999,np.nan)\n",
    "    x_test = pre.clean_value(x_test,-999,np.nan)\n",
    "    \n",
    "    \"\"\"\n",
    "    pre.PCA_visualize(x_train,label = i)\n",
    "    \n",
    "    mean,eigvecs,eigvals = pre.get_PCA(x_train)\n",
    "    x_test = x_test - mean\n",
    "    \n",
    "    x_train = pre.reduce_PCA(eigvecs,x_train,10)\n",
    "    x_test = pre.reduce_PCA(eigvecs,x_test,10)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train,mean,stdev =  pre.standardize_data(x_train)\n",
    "    x_test,_,_ = pre.standardize_data(x_test, mean,stdev)\n",
    "    \n",
    "    x_train = pre.clean_value(x_train,np.nan,0,inplace = True)\n",
    "    x_test = pre.clean_value(x_test,np.nan,0,inplace = True)\n",
    "    \n",
    "    \n",
    "    x_train = pre.build_poly(x_train, degre_polys[i])\n",
    "    x_test = pre.build_poly(x_test,degre_polys[i])\n",
    "    x_train = np.c_[np.ones((x_train.shape[0], 1)), x_train]\n",
    "    x_test = np.c_[np.ones((x_test.shape[0], 1)), x_test]\n",
    "    \n",
    "    clean_data_trains.append((x_train,y_train))\n",
    "    clean_data_tests.append((x_test,test_indx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We now need to standardize the function so that they all take the same type of parameters as inputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w = np.random.rand(clean_data_tests[0][0].shape[1])\n",
    "maxiters = 100\n",
    "gamma = 0.01\n",
    "\n",
    "#method 1\n",
    "meth1 = lambda  y, x: lst.ridge_regression(y,x,5.17E-5)\n",
    "\n",
    "if (len(clean_data_tests) > 1):\n",
    "    init_w2 = np.random.rand(clean_data_tests[1][0].shape[1])\n",
    "    #method 2\n",
    "    #reg_log_reg = lambda y,x : log.reg_logistic_regression(y, x, lambda_, init_w2, maxiters, gamma)\n",
    "    #meth2 = lambda  y, x: log.logistic_regression(y,x,init_w2,5,gamma)\n",
    "    meth2 = lambda y,x : lst.ridge_regression(y,x,0.0013)\n",
    "\n",
    "    init_w3 = np.random.rand(clean_data_tests[2][0].shape[1])\n",
    "    #method 3\n",
    "    lambda_ = 0.1\n",
    "    meth3 = lambda y, x: lst.ridge_regression(y,x,0.001389)\n",
    "    #log_reg3 = lambda  y, x: log.logistic_regression(y,x,init_w3,5,gamma)\n",
    "\n",
    "methods = [meth1,meth2,meth3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this point we try the different models defined in the cell above: to do so run the cell below, and check the obtained accuracies._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies_group_means = []\n",
    "accuracies_group_stds = []\n",
    "for round_,((x_train,y_train),meth) in enumerate(zip(clean_data_trains,methods)):\n",
    "    print(\"#################################\")\n",
    "    print(\"**********treating the {i}th group of data:**************\".format(i = round_+1))\n",
    "    acc_mean, acc_std = spl.k_fold_cv(y_train,x_train,5,meth)\n",
    "    accuracies_group_means.append(acc_mean)\n",
    "    accuracies_group_stds.append(acc_std)\n",
    "print(\"done! Obtained accuracies:\",[np.mean(i) for i in accuracies_group_means])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ridge: for every models test different lambdas and degrees\n",
    "degrees = np.arange(1, 3)\n",
    "lambdas = np.logspace(-5, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies_tot = []\n",
    "\n",
    "for idx_subset, (x_train, y_train) in enumerate(clean_data_trains):\n",
    "    print('##### START SUBSET {} #####'.format(idx_subset))\n",
    "    accuracies = np.zeros((len(lambdas), len(degrees)))\n",
    "    for idx_deg, deg in enumerate(degrees):\n",
    "        x_poly = pre.build_poly(x_train, deg)\n",
    "        \n",
    "        for idx_lambda, lambda_ in enumerate(lambdas):\n",
    "            ridge = lambda y, x: lst.ridge_regression(y,x,lambda_)\n",
    "            _, k_accuracies_test = spl.k_fold_cv(y_train, x_poly, 2, ridge)\n",
    "            \n",
    "            # update table\n",
    "            accuracies[idx_lambda][idx_deg] = np.mean(k_accuracies_test)\n",
    "    \n",
    "    accuracies_tot.append(accuracies)\n",
    "    print('##### END SUBSET {} #####'.format(idx_subset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save accuracies\n",
    "import pickle\n",
    "\n",
    "with open('acc_ridge.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(accuracies_tot, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.subplots(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "fig = sns.heatmap(accuracies_tot[0])\n",
    "fig.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "fig.set_xticklabels(degrees)\n",
    "fig.set_xlabel('degree')\n",
    "fig.set_ylabel('lambda')\n",
    "fig.set_title('Accuracy - subset 0')\n",
    "plt.subplot(1,3,2)\n",
    "fig = sns.heatmap(accuracies_tot[1])\n",
    "fig.set_xticklabels(degrees)\n",
    "fig.set_xlabel('degree')\n",
    "fig.set_ylabel('lambda')\n",
    "fig.set_title('Accuracy - subset 1')\n",
    "plt.subplot(1,3,3)\n",
    "fig = sns.heatmap(accuracies_tot[2])\n",
    "fig.set_xticklabels(degrees)\n",
    "fig.set_xlabel('degree')\n",
    "fig.set_ylabel('lambda')\n",
    "fig.set_title('Accuracy - subset 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt version\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "ax0, ax1, ax2 = axes.flatten()\n",
    "\n",
    "d0 = ax0.imshow(accuracies_tot[0], cmap='GnBu', aspect='auto')\n",
    "ax0.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "plt.xticks(degrees)\n",
    "ax0.set_xlabel('degree', fontsize=12)\n",
    "ax0.set_ylabel('lambda', fontsize=12)\n",
    "ax0.set_title('Subset 0', fontsize=15)\n",
    "fig.colorbar(d0, ax=ax0)\n",
    "\n",
    "d1 = ax1.imshow(accuracies_tot[1], cmap='GnBu', aspect='auto')\n",
    "ax1.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "ax1.set_xlabel('degree', fontsize=12)\n",
    "ax1.set_ylabel('')\n",
    "ax1.set_title('Subset 1', fontsize=15)\n",
    "fig.colorbar(d1, ax=ax1)\n",
    "\n",
    "d2 = ax2.imshow(accuracies_tot[2], cmap='GnBu', aspect='auto')\n",
    "ax2.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "#plt.xticks(degrees)\n",
    "ax2.set_xlabel('degree', fontsize=12)\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('Subset 2', fontsize=15)\n",
    "fig.colorbar(d2, ax=ax2)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save figure\n",
    "fig.savefig(\"heatmaps.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: ↓ (lambdas), x: → (degree)\n",
    "for nb, acc in enumerate(accuracies_tot):\n",
    "    print('SUBSET {}'.format(nb))\n",
    "    ymax = np.asscalar(np.where(acc == np.max(acc))[0])\n",
    "    xmax = np.asscalar(np.where(acc == np.max(acc))[1])\n",
    "    \n",
    "    print('Best degree for subset {}: {}'.format(nb, degrees[xmax]))\n",
    "    print('Best lambda for subset {}: {}'.format(nb, lambdas[ymax]))\n",
    "    print('Accuracy: {}'.format(acc[ymax][xmax]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-5, 0, 10)\n",
    "plt.figure(1, figsize=(16, 16))\n",
    "for idx_subset, (x_train, y_train) in enumerate(clean_data_trains):\n",
    "    accuracy_train = []\n",
    "    accuracy_test = []\n",
    "    \n",
    "    for idx_lambda, lambda_ in enumerate(lambdas):\n",
    "            ridge = lambda y, x: lst.ridge_regression(y,x,lambda_)\n",
    "            \n",
    "            k_accuracies_train, k_accuracies_test = spl.k_fold_cv(y_train, x_train, 10, ridge, hlp.accuracy)\n",
    "            \n",
    "            plt.subplot(3, 3, idx_subset+1)\n",
    "            plt.title(\"Cross validation for training of categorical subset {i}\".format(i=idx_subset))\n",
    "            viz.visualize_boxplot_cross_validation(k_accuracies_train, [idx_lambda])\n",
    "            \n",
    "            plt.subplot(3, 3, 4+idx_subset)\n",
    "            plt.title(\"Cross validation for testing of categorical subset {i}\".format(i=idx_subset))\n",
    "            viz.visualize_boxplot_cross_validation(k_accuracies_test, [idx_lambda])\n",
    "        \n",
    "            accuracy_train.append(np.mean(k_accuracies_train))\n",
    "            accuracy_test.append(np.mean(k_accuracies_test))\n",
    "            \n",
    "    plt.subplot(3, 3, idx_subset+7)\n",
    "    plt.title(\"Cross validation of subset {i}\".format(i=idx_subset))\n",
    "    viz.cross_validation_visualization(lambdas, accuracy_train, accuracy_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We now interpolate the data thanks to the model defined 2 cells higher..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = np.zeros(len(tX_test))\n",
    "assert(len(tX_test) == sum([i[0].shape[0] for i in clean_data_tests]))\n",
    "for (x_test,y_indx),(x_train,y_train),meth in zip(clean_data_tests,clean_data_trains,methods):\n",
    "    w_fin,loss = meth(y_train,x_train)\n",
    "    y_test = x_test @ w_fin\n",
    "    y_test = [-1 if i < 0 else 1.0 for i in y_test]\n",
    "    y_submit[y_indx] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_And finally save the results to csv._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.create_csv_submission(ids_test,y_submit,\"anakin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put your useful trash here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trash random dataframe\n",
    "np.random.seed(2)\n",
    "df = pd.DataFrame(np.random.randint(-1002,-995,size =(3,4)), columns=list('ABCD'))\n",
    "df.replace(to_replace = -999,value = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Yann\n",
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
