{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='pipeline.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logistic as log\n",
    "import split as spl\n",
    "import least_squares as lst\n",
    "import helpers as hlp\n",
    "import pre_processing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd # cannot use external libraries, just pandas for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y, tX, ids = hlp.load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = hlp.load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tX.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_TRAIN_PATH)\n",
    "test_data = pd.read_csv(DATA_TEST_PATH)\n",
    "dic = {'s':1,'b':-1}\n",
    "data.Prediction = data.Prediction.map(dic)\n",
    "test_data.Prediction = test_data.Prediction.map(dic)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.isin([-999]).any(axis = 1)\n",
    "print(len(data[mask]))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The vast majoriy of our data has -999 values: we'd better handle it carefully_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.replace(to_replace = -999,value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace_val = np.nan\n",
    "#tX = np.where(tX == -999,replace_val,tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.nanstd(tX,axis = 0)\n",
    "mean = np.nanmean(tX,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: {} samples x {} features'.format(pd.DataFrame(tX).shape[0], pd.DataFrame(tX).shape[1]))\n",
    "print('Test set size: {} samples x {} features'.format(test_data.shape[0], pd.DataFrame(tX).shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totrash before submit: we use pandas to know to which index PRI_jet_num does correspond.\n",
    "np.where(data.columns.values == \"PRI_jet_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trains = spl.split_categorical_data(tX,22,labels = y,split = False)\n",
    "data_tests = spl.split_categorical_data(tX_test,22,split = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "stdev = 0\n",
    "clean_data_trains = []\n",
    "clean_data_tests = []\n",
    "for (x_train,y_train),(x_test,_) in zip(data_trains,data_tests):\n",
    "    x_train,x_test = pre.clean_variance(x_train,x_test)\n",
    "    \n",
    "    x_train = pre.clean_value(x_train,-999,np.nan)\n",
    "    x_test = pre.clean_value(x_test,-999,np.nan)\n",
    "    \n",
    "    x_train,mean,stdev =  pre.standardize_data(x_train)\n",
    "    x_test,_,_ = pre.standardize_data(x_test, mean,stdev)\n",
    "    \n",
    "    x_train = pre.clean_value(x_train,np.nan,0,inplace = True)\n",
    "    x_test = pre.clean_value(x_test,np.nan,0,inplace = True)\n",
    "    \n",
    "    x_train = np.c_[np.ones((x_train.shape[0], 1)), x_train]\n",
    "    x_test = np.c_[np.ones((x_test.shape[0], 1)), x_test]\n",
    "    \n",
    "    clean_data_trains.append((x_train,y_train))\n",
    "    clean_data_tests.append((x_test,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We now need to standardize the function so that they all take the same type of parameters as inputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w = np.random.rand(x_train.shape[1])\n",
    "maxiters = 100\n",
    "gamma = 0.01\n",
    "\n",
    "#method 1\n",
    "log_reg = lambda  y, x: log.logistic_regression(y_train,x_train,init_w,maxiters,gamma)\n",
    "\n",
    "#method 2\n",
    "reg_log_reg = lambda y,x : log.reg_logistic_regression(y_train, x_train, lambda_, init_w, maxiters, gamma)\n",
    "\n",
    "#method 3\n",
    "ridge = lambda y, x: lst.ridge_regression(y,x,lambda_)\n",
    "\n",
    "methods = [log_reg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this point we try the different models defined in the cell above: to do so run the cell below, and check the obtained accuracies._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_group_means = []\n",
    "accuracies_group_stds = []\n",
    "for round_,((x_train,y_train),meth) in enumerate(zip(clean_data_trains,methods)):\n",
    "    print(\"#################################\")\n",
    "    print(\"**********treating the {i}th group of data:**************\".format(i = round_+1))\n",
    "    acc_mean, acc_std = spl.k_fold_cv(y_train,x_train,2,meth)\n",
    "    accuracies_group_means.append(acc_mean)\n",
    "    accuracies_group_stds.append(acc_std)\n",
    "print(\"done! Obtained accuracies:\",accuracies_group_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We now interpolate the data thanks to the model defined 2 cells higher..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = []\n",
    "for (x_test,y_test),meth in zip(clean_data_tests,methods):\n",
    "    w_fin,loss = meth(y_train,x_train)\n",
    "    y_test = x_test @ w_fin\n",
    "    print(y_test)\n",
    "    y_test = [-1-0 if i < 0.5 else 1.0 for i in y_test]\n",
    "    y_submit.append(y_test)\n",
    "y_submit = np.concatenate(y_submit,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_And finally save the results to csv._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.create_csv_submission(ids_test,y_submit,\"obiwan.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gianni's corner\n",
    "_desole mec, javais cru que tu modifierais mon code: comme la cellule avait pas changé, javais pensé que tavais pas modifié mon code dans le main, seulement les fctions ==> jai pas pensé a scroller plus bas :/ jy ai quand meme laissé dans le doute_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "x_trains = spl.split_categorical_data(tX,22,labels = y,split = True)\n",
    "x_tests = spl.split_categorical_data(tX_test,22,split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "# Sanity check\n",
    "print('Shape of category 0: {} x {}'.format(x_trains[0][0].shape[0], x_trains[0][0].shape[1]))\n",
    "print('Shape of category 1: {} x {}'.format(x_trains[1][0].shape[0], x_trains[1][0].shape[1]))\n",
    "print('Shape of category 2 and 3: {} x {}'.format(x_trains[2][0].shape[0], x_trains[2][0].shape[1]))\n",
    "\n",
    "print('Total: {}'.format(x_trains[0][0].shape[0] + x_trains[1][0].shape[0] + x_trains[2][0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "reduced_x_trains = []\n",
    "reduced_x_tests = []\n",
    "for i in range(len(x_trains)):\n",
    "    tr = x_trains[i][0]\n",
    "    te = x_tests[i]\n",
    "    \n",
    "    x_tr, x_te = pre.clean_variance(tr, te, inplace=False)\n",
    "    reduced_x_trains.append((x_tr, x_trains[i][1])) # x_trains[i][1] = labels\n",
    "    reduced_x_tests.append(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "# Sanity check\n",
    "print('Shape of category 0 (train): {} x {}'.format(reduced_x_trains[0][0].shape[0], reduced_x_trains[0][0].shape[1]))\n",
    "print('Shape of category 0 (test): {} x {}'.format(reduced_x_tests[0].shape[0], reduced_x_tests[0].shape[1]))\n",
    "\n",
    "print('Shape of category 1 (train): {} x {}'.format(reduced_x_trains[1][0].shape[0], reduced_x_trains[1][0].shape[1]))\n",
    "print('Shape of category 1 (test): {} x {}'.format(reduced_x_tests[1].shape[0], reduced_x_tests[1].shape[1]))\n",
    "\n",
    "print('Shape of category 2 and 3 (train): {} x {}'.format(reduced_x_trains[2][0].shape[0], reduced_x_trains[2][0].shape[1]))\n",
    "print('Shape of category 2 and 3 (test): {} x {}'.format(reduced_x_tests[2].shape[0], reduced_x_tests[2].shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "# on veut clean les variances nulles dans le train ET dans le test\n",
    "# we don't care about labels here\n",
    "#for (tr, te) in zip(x_trains[0], x_test[0]):\n",
    "#    blablabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "std_train_0, mu_0, sigma_0 = pre.standardize_data(reduced_x_trains[0][0])\n",
    "std_test_0, mu_0, sigma_0 = pre.standardize_data(reduced_x_tests[0], mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "# Sanity check\n",
    "print('Shape of category 0 (std train): {} x {}'.format(std_train_0.shape[0], std_train_0.shape[1]))\n",
    "print('Shape of category 0 (std test): {} x {}'.format(std_test_0.shape[0], std_test_0.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put your useful trash here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trash random dataframe\n",
    "np.random.seed(2)\n",
    "df = pd.DataFrame(np.random.randint(-1002,-995,size =(3,4)), columns=list('ABCD'))\n",
    "df.replace(to_replace = -999,value = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Yann\n",
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
