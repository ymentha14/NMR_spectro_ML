{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='../data/pipeline.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logistic as log\n",
    "import split as spl\n",
    "import least_squares as lst\n",
    "import helpers as hlp\n",
    "import pre_processing as pre\n",
    "import vizu as viz\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "DATA_TEST_PATH = '../data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd # cannot use external libraries, just pandas for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y, tX, ids = hlp.load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = hlp.load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tX.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFOLD = 4\n",
    "METRIC = hlp.accuracy\n",
    "LAMBDAS_OPTS = []\n",
    "DEGREES_POLY = []\n",
    "degrees = np.arange(1, 14,2)\n",
    "lambdas = np.logspace(-5, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_TRAIN_PATH)\n",
    "test_data = pd.read_csv(DATA_TEST_PATH)\n",
    "dic = {'s':1,'b':-1}\n",
    "data.Prediction = data.Prediction.map(dic)\n",
    "test_data.Prediction = test_data.Prediction.map(dic)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.isin([-999]).any(axis = 1)\n",
    "print(len(data[mask]))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The vast majoriy of our data has -999 values: we'd better handle it carefully_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.replace(to_replace = -999,value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace_val = np.nan\n",
    "#tX = np.where(tX == -999,replace_val,tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.nanstd(tX,axis = 0)\n",
    "mean = np.nanmean(tX,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: {} samples x {} features'.format(pd.DataFrame(tX).shape[0], pd.DataFrame(tX).shape[1]))\n",
    "print('Test set size: {} samples x {} features'.format(test_data.shape[0], pd.DataFrame(tX).shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class separation - Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(data.columns)[2:]\n",
    "\n",
    "data_0 = data[data['PRI_jet_num'] == 0]\n",
    "data_1 = data[data['PRI_jet_num'] == 1]\n",
    "data_2 = data[data['PRI_jet_num'] >= 2]\n",
    "\n",
    "#fig, axes = plt.subplots(30, 1, figsize=(8, 150), sharex=False)\n",
    "for idx, name in enumerate(col_names):  \n",
    "    \"\"\"\n",
    "    axes[idx].hist(data_0[name], bins=50, density=True, alpha=0.3, label='class 0')\n",
    "    axes[idx].hist(data_1[name], bins=50, density=True, alpha=0.3, label='class 1')\n",
    "    axes[idx].hist(data_2[name], bins=50, density=True, alpha=0.3, label='class 2 & 3')\n",
    "    axes[idx].set_title(name)\n",
    "    axes[idx].legend()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "ax0, ax1, ax2, ax3 = axes.flatten()\n",
    "\n",
    "ax0.hist(data_0['DER_mass_transverse_met_lep'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax0.hist(data_1['DER_mass_transverse_met_lep'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax0.hist(data_2['DER_mass_transverse_met_lep'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax0.legend()\n",
    "ax0.set_xlabel('Value', fontsize=10)\n",
    "ax0.set_ylabel('Proportion', fontsize=10)\n",
    "ax0.set_title('DER_mass_transverse_met_lep', fontsize=12)\n",
    "\n",
    "ax1.hist(data_0['DER_deltar_tau_lep'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax1.hist(data_1['DER_deltar_tau_lep'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax1.hist(data_2['DER_deltar_tau_lep'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Value', fontsize=10)\n",
    "ax1.set_ylabel('Proportion', fontsize=10)\n",
    "ax1.set_title('DER_deltar_tau_lep',fontsize=12)\n",
    "\n",
    "ax2.hist(data_0['DER_sum_pt'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax2.hist(data_1['DER_sum_pt'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax2.hist(data_2['DER_sum_pt'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Value', fontsize=10)\n",
    "ax2.set_ylabel('Proportion', fontsize=10)\n",
    "ax2.set_title('DER_sum_pt', fontsize=12)\n",
    "\n",
    "\n",
    "ax3.hist(data_0['PRI_met_sumet'], bins=50, density=True, alpha=0.3, label='class 0', edgecolor='w', lw=.5)\n",
    "ax3.hist(data_1['PRI_met_sumet'], bins=50, density=True, alpha=0.3, label='class 1', edgecolor='w', lw=.5)\n",
    "ax3.hist(data_2['PRI_met_sumet'], bins=50, density=True, alpha=0.3, label='class 2 & 3', edgecolor='w', lw=.5)\n",
    "ax3.legend()\n",
    "#ax3.ticklabel_format(useMathText=True)\n",
    "#ax3.yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2e'))\n",
    "ax3.set_xlabel('Value', fontsize=10)\n",
    "ax3.set_ylabel('Proportion', fontsize=10)\n",
    "ax3.set_title('PRI_met_sumet', fontsize=12)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save figure\n",
    "fig.savefig(\"../results/classes_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totrash before submit: we use pandas to know to which index PRI_jet_num does correspond.\n",
    "np.where(data.columns.values == \"PRI_jet_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trains = spl.split_categorical_data(tX,22,labels = y,split = True)\n",
    "data_tests = spl.split_categorical_data(tX_test,22,split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "stdev = 0\n",
    "clean_data_trains = []\n",
    "clean_data_tests = []\n",
    "for i,((x_train,y_train),(x_test,test_indx)) in enumerate(zip(data_trains,data_tests)):\n",
    "    x_train,x_test = pre.clean_variance(x_train,x_test)\n",
    "    \n",
    "    x_train = pre.clean_value(x_train,-999,np.nan)\n",
    "    x_test = pre.clean_value(x_test,-999,np.nan)\n",
    "    \n",
    "    \"\"\"\n",
    "    pre.PCA_visualize(x_train,label = i)\n",
    "    \n",
    "    mean,eigvecs,eigvals = pre.get_PCA(x_train)\n",
    "    x_test = x_test - mean\n",
    "    \n",
    "    x_train = pre.reduce_PCA(eigvecs,x_train,10)\n",
    "    x_test = pre.reduce_PCA(eigvecs,x_test,10)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train,mean,stdev =  pre.standardize_data(x_train)\n",
    "    x_test,_,_ = pre.standardize_data(x_test, mean,stdev)\n",
    "    \n",
    "    x_train = pre.clean_value(x_train,np.nan,0,inplace = True)\n",
    "    x_test = pre.clean_value(x_test,np.nan,0,inplace = True)\n",
    "    \n",
    "    x_train = np.c_[np.ones((x_train.shape[0], 1)), x_train]\n",
    "    x_test = np.c_[np.ones((x_test.shape[0], 1)), x_test]\n",
    "    \n",
    "    clean_data_trains.append((x_train,y_train))\n",
    "    clean_data_tests.append((x_test,test_indx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ridge: for every models test different lambdas and degrees\n",
    "\n",
    "#averages of the f1/accuracy over the kfold for each cell\n",
    "metrics_tot = []\n",
    "\n",
    "#higher level: we keep the k_metrics_train,k_metrics_test and optcutoffs in a similar table\n",
    "save_metrics = []\n",
    "\n",
    "for idx_subset, (x_train, y_train) in enumerate(clean_data_trains):\n",
    "    print('##### START SUBSET {} #####'.format(idx_subset))\n",
    "    save_metric  = []\n",
    "    \n",
    "    for idx_deg, deg in enumerate(degrees):\n",
    "        x_poly = pre.build_poly(x_train, deg)\n",
    "        temp1 = []\n",
    "        print(\"{d}/{D} row\".format(d = idx_deg,D = D))\n",
    "        for idx_lambda, lambda_ in enumerate(lambdas):\n",
    "            ridge = lambda y, x: lst.ridge_regression(y,x,lambda_)\n",
    "            \n",
    "            start = datetime.datetime.now()\n",
    "\n",
    "            k_metrics_train, k_metrics_test,_ = spl.k_fold_cv(y_train, x_poly, KFOLD, ridge,METRIC,verbose = False)\n",
    "            \n",
    "            end = datetime.datetime.now()\n",
    "            remain = end - start\n",
    "            remain = float(remain.total_seconds())* (L * D * (3 - idx_subset) - idx_deg * L - idx_lambda)/60\n",
    "            print(\"{i}/{L} column\".format(i = idx_lambda,L = L))\n",
    "            print(\"remaining time {} min \".format(remain))\n",
    "            temp1.append([k_metrics_train,k_metrics_test])\n",
    "            \n",
    "            # update table\n",
    "        save_metric.append(temp1)\n",
    "    save_metrics.append(save_metric)\n",
    "    print('##### END SUBSET {} #####'.format(idx_subset))\n",
    "\n",
    "for group in save_metrics:\n",
    "    metrics_tot.append(np.array([[np.mean(lam[1]) for lam in deg]for deg in group]).T)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save accuracies\n",
    "import pickle\n",
    "\n",
    "with open('../backup/'+ hlp.dico[METRIC] + '_metrics_tot.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(metrics_tot, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( save_metrics, open( \"../backup/\"+ hlp.dico[METRIC] + \"_save_metrics.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics = pickle.load(open( \"../backup/\"+ hlp.dico[METRIC] + \"_save_metrics.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "ax0, ax1, ax2 = axes.flatten()\n",
    "\n",
    "d0 = ax0.imshow(metrics_tot[0], cmap='GnBu', aspect='auto')\n",
    "ax0.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "#ax0.set_xticklabels(degrees)\n",
    "plt.xticks(degrees)\n",
    "ax0.set_xlabel('degree', fontsize=12)\n",
    "ax0.set_ylabel('lambda', fontsize=12)\n",
    "ax0.set_title('Subset 0', fontsize=15)\n",
    "fig.colorbar(d0, ax=ax0)\n",
    "\n",
    "d1 = ax1.imshow(metrics_tot[1], cmap='GnBu', aspect='auto')\n",
    "ax1.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "#ax1.set_xticklabels(degrees)\n",
    "#plt.xticks(degrees)\n",
    "#plt.gca().set_xticks(degrees)\n",
    "ax1.set_xlabel('degree', fontsize=12)\n",
    "ax1.set_ylabel('')\n",
    "ax1.set_title('Subset 1', fontsize=15)\n",
    "fig.colorbar(d1, ax=ax1)\n",
    "\n",
    "d2 = ax2.imshow(metrics_tot[2], cmap='GnBu', aspect='auto')\n",
    "ax2.set_yticklabels(np.round(lambdas, 5), rotation=60)\n",
    "#ax2.set_xticklabels(degrees)\n",
    "#plt.xticks(degrees)\n",
    "ax2.set_xlabel('degree', fontsize=12)\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('Subset 2', fontsize=15)\n",
    "fig.colorbar(d2, ax=ax2)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: ↓ (lambdas), x: → (degree)\n",
    "\n",
    "#we save the 3 best indexes for the degree\n",
    "best_degrees = []\n",
    "for nb, met in enumerate(metrics_tot):\n",
    "    print('SUBSET {}'.format(nb))\n",
    "    ymax = np.asscalar(np.where(met == np.max(met))[0])\n",
    "    xmax = np.asscalar(np.where(met == np.max(met))[1])\n",
    "    best_degrees.append(xmax)\n",
    "    \n",
    "    print('Best degree for subset {}: {}'.format(nb, degrees[xmax]))\n",
    "    DEGREES_POLY.append(degrees[xmax])\n",
    "    \n",
    "    print('Best lambda for subset {}: {}'.format(nb, lambdas[ymax]))\n",
    "    LAMBDAS_OPTS.append(lambdas[ymax])\n",
    "    print(hlp.dico[METRIC] + ': {}'.format(met[ymax][xmax]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(16,16))\n",
    "ax = axes.flatten()\n",
    "\n",
    "for idx_subset,(deg,save_metric) in enumerate(zip(best_degrees,save_metrics)):\n",
    "    accuracy_train = []\n",
    "    accuracy_test = []\n",
    "    best_column = np.array(save_metric)[deg,:]\n",
    "    \n",
    "    for idx_lambda,k_result in enumerate(best_column):\n",
    "        k_accuracies_train, k_accuracies_test = k_result\n",
    "        viz.visualize_boxplot_cross_validation2(k_accuracies_train,[idx_lambda], ax[idx_subset], idx_subset, True)\n",
    "        viz.visualize_boxplot_cross_validation2(k_accuracies_train,[idx_lambda], ax[idx_subset+3], idx_subset, False)\n",
    "\n",
    "        accuracy_train.append(np.mean(k_accuracies_train))\n",
    "        accuracy_test.append(np.mean(k_accuracies_test))\n",
    "    viz.cross_validation_visualization(lambdas, accuracy_train, accuracy_test, ax[idx_subset+6], idx_subset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We now need to standardize the function so that they all take the same type of parameters as inputs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kfold for the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w = np.random.rand(clean_data_tests[0][0].shape[1])\n",
    "maxiters = 100\n",
    "gamma = 0.01\n",
    "\n",
    "#method 1\n",
    "meth1 = lambda  y, x: lst.ridge_regression(y,x,5.1794746792312125e-05)\n",
    "\n",
    "if (len(clean_data_tests) > 1):\n",
    "    #method 2\n",
    "    init_w2 = np.random.rand(clean_data_tests[1][0].shape[1])\n",
    "    #reg_log_reg = lambda y,x : log.reg_logistic_regression(y, x, lambda_, init_w2, maxiters, gamma)\n",
    "    #meth2 = lambda  y, x: log.logistic_regression(y,x,init_w2,5,gamma)\n",
    "    meth2 = lambda y,x : lst.ridge_regression(y,x,0.0013894954943731374)\n",
    "\n",
    "    #method 3\n",
    "    init_w3 = np.random.rand(clean_data_tests[2][0].shape[1])\n",
    "    lambda_ = 0.1\n",
    "    meth3 = lambda y, x: lst.ridge_regression(y,x,0.00138944954943731374)\n",
    "    #log_reg3 = lambda  y, x: log.logistic_regression(y,x,init_w3,5,gamma)\n",
    "\n",
    "methods = [meth1,meth2,meth3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_group_means = []\n",
    "metrics_group_stds = []\n",
    "cutoffs_group = []\n",
    "degre_polys = [12,12,13]\n",
    "for round_,((x_train,y_train),meth,deg) in enumerate(zip(clean_data_trains,methods,degre_polys)):\n",
    "    print(\"#################################\")\n",
    "    print(\"**********treating the {i}th group of data:**************\".format(i = round_+1))\n",
    "    x_poly = pre.build_poly(x_train, deg)\n",
    "    metrics, metric_stds,opt_cutoffs = spl.k_fold_cv(y_train,x_poly,5,meth,metric = METRIC)\n",
    "    metrics_group_means.append(metrics)\n",
    "    metrics_group_stds.append(metric_stds)\n",
    "    cutoffs_group.append(opt_cutoffs)\n",
    "print(\"\\n done! Obtained :\" + hlp.dico[METRIC],[np.mean(i) for i in metrics_group_means])\n",
    "print(\"ideal cutoffs for these groups-methods pairs:\",[np.mean(i) for i in cutoffs_group])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We now interpolate the data thanks to the model defined 2 cells higher..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = np.zeros(len(tX_test))\n",
    "assert(len(tX_test) == sum([i[0].shape[0] for i in clean_data_tests]))\n",
    "for (x_test,y_indx),(x_train,y_train),meth,deg in zip(clean_data_tests,clean_data_trains,methods,degre_polys):\n",
    "    x_poly_tr = pre.build_poly(x_train, deg)\n",
    "    x_poly_te = pre.build_poly(x_test,deg)\n",
    "    w_fin,loss = meth(y_train,x_poly_tr)\n",
    "    y_test = x_poly_te @ w_fin\n",
    "    cut = spl.get_best_cutoff(x_poly_tr,y_train,w_fin,METRIC)\n",
    "    y_test = [-1 if i < cut else 1.0 for i in y_test]\n",
    "    y_submit[y_indx] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_And finally save the results to csv._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.create_csv_submission(ids_test,y_submit,\"../darth_mole.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
