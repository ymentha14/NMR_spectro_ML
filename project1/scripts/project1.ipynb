{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd # cannot use external libraries, just pandas for data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "print(tX.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>s</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>b</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>b</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>b</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100005</td>\n",
       "      <td>b</td>\n",
       "      <td>89.744</td>\n",
       "      <td>13.550</td>\n",
       "      <td>59.149</td>\n",
       "      <td>116.344</td>\n",
       "      <td>2.636</td>\n",
       "      <td>284.584</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>1.362</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237</td>\n",
       "      <td>282.849</td>\n",
       "      <td>3</td>\n",
       "      <td>90.547</td>\n",
       "      <td>-2.412</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>56.165</td>\n",
       "      <td>0.224</td>\n",
       "      <td>3.106</td>\n",
       "      <td>193.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100006</td>\n",
       "      <td>s</td>\n",
       "      <td>148.754</td>\n",
       "      <td>28.862</td>\n",
       "      <td>107.782</td>\n",
       "      <td>106.130</td>\n",
       "      <td>0.733</td>\n",
       "      <td>158.359</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.941</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.443</td>\n",
       "      <td>294.074</td>\n",
       "      <td>2</td>\n",
       "      <td>123.010</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.450</td>\n",
       "      <td>56.867</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>179.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100007</td>\n",
       "      <td>s</td>\n",
       "      <td>154.916</td>\n",
       "      <td>10.418</td>\n",
       "      <td>94.714</td>\n",
       "      <td>29.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.897</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.761</td>\n",
       "      <td>187.299</td>\n",
       "      <td>1</td>\n",
       "      <td>30.638</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100008</td>\n",
       "      <td>b</td>\n",
       "      <td>105.594</td>\n",
       "      <td>50.559</td>\n",
       "      <td>100.989</td>\n",
       "      <td>4.288</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>129.804</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100009</td>\n",
       "      <td>s</td>\n",
       "      <td>128.053</td>\n",
       "      <td>88.941</td>\n",
       "      <td>69.272</td>\n",
       "      <td>193.392</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845</td>\n",
       "      <td>294.741</td>\n",
       "      <td>1</td>\n",
       "      <td>167.735</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>-2.514</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>167.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100010</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>86.240</td>\n",
       "      <td>79.692</td>\n",
       "      <td>27.201</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688</td>\n",
       "      <td>250.178</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100011</td>\n",
       "      <td>b</td>\n",
       "      <td>114.744</td>\n",
       "      <td>10.286</td>\n",
       "      <td>75.712</td>\n",
       "      <td>30.816</td>\n",
       "      <td>2.563</td>\n",
       "      <td>252.599</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>2.888</td>\n",
       "      <td>...</td>\n",
       "      <td>2.148</td>\n",
       "      <td>290.547</td>\n",
       "      <td>3</td>\n",
       "      <td>76.773</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>0.303</td>\n",
       "      <td>56.876</td>\n",
       "      <td>1.773</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>165.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100012</td>\n",
       "      <td>b</td>\n",
       "      <td>145.297</td>\n",
       "      <td>64.234</td>\n",
       "      <td>103.565</td>\n",
       "      <td>106.999</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.183</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907</td>\n",
       "      <td>232.362</td>\n",
       "      <td>1</td>\n",
       "      <td>93.117</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>1.943</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>93.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100013</td>\n",
       "      <td>b</td>\n",
       "      <td>82.488</td>\n",
       "      <td>31.663</td>\n",
       "      <td>64.128</td>\n",
       "      <td>8.232</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433</td>\n",
       "      <td>163.420</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100014</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>109.412</td>\n",
       "      <td>14.398</td>\n",
       "      <td>17.323</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.472</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.583</td>\n",
       "      <td>198.616</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100015</td>\n",
       "      <td>s</td>\n",
       "      <td>111.026</td>\n",
       "      <td>32.096</td>\n",
       "      <td>75.271</td>\n",
       "      <td>23.067</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.205</td>\n",
       "      <td>...</td>\n",
       "      <td>2.415</td>\n",
       "      <td>122.176</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100016</td>\n",
       "      <td>b</td>\n",
       "      <td>114.256</td>\n",
       "      <td>4.351</td>\n",
       "      <td>67.963</td>\n",
       "      <td>47.221</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.954</td>\n",
       "      <td>...</td>\n",
       "      <td>2.055</td>\n",
       "      <td>191.568</td>\n",
       "      <td>1</td>\n",
       "      <td>36.263</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>36.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100017</td>\n",
       "      <td>s</td>\n",
       "      <td>127.861</td>\n",
       "      <td>50.953</td>\n",
       "      <td>77.267</td>\n",
       "      <td>26.967</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.833</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.975</td>\n",
       "      <td>211.720</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100018</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>85.186</td>\n",
       "      <td>68.827</td>\n",
       "      <td>5.042</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.116</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.033</td>\n",
       "      <td>151.816</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100019</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>88.767</td>\n",
       "      <td>115.058</td>\n",
       "      <td>15.337</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.879</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.577</td>\n",
       "      <td>115.145</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Prediction  DER_mass_MMC  DER_mass_transverse_met_lep  \\\n",
       "0   100000          s       138.470                       51.655   \n",
       "1   100001          b       160.937                       68.768   \n",
       "2   100002          b      -999.000                      162.172   \n",
       "3   100003          b       143.905                       81.417   \n",
       "4   100004          b       175.864                       16.915   \n",
       "5   100005          b        89.744                       13.550   \n",
       "6   100006          s       148.754                       28.862   \n",
       "7   100007          s       154.916                       10.418   \n",
       "8   100008          b       105.594                       50.559   \n",
       "9   100009          s       128.053                       88.941   \n",
       "10  100010          b      -999.000                       86.240   \n",
       "11  100011          b       114.744                       10.286   \n",
       "12  100012          b       145.297                       64.234   \n",
       "13  100013          b        82.488                       31.663   \n",
       "14  100014          b      -999.000                      109.412   \n",
       "15  100015          s       111.026                       32.096   \n",
       "16  100016          b       114.256                        4.351   \n",
       "17  100017          s       127.861                       50.953   \n",
       "18  100018          b      -999.000                       85.186   \n",
       "19  100019          b      -999.000                       88.767   \n",
       "\n",
       "    DER_mass_vis  DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "0         97.827    27.980                 0.910           124.711   \n",
       "1        103.235    48.146              -999.000          -999.000   \n",
       "2        125.953    35.635              -999.000          -999.000   \n",
       "3         80.943     0.414              -999.000          -999.000   \n",
       "4        134.805    16.405              -999.000          -999.000   \n",
       "5         59.149   116.344                 2.636           284.584   \n",
       "6        107.782   106.130                 0.733           158.359   \n",
       "7         94.714    29.169              -999.000          -999.000   \n",
       "8        100.989     4.288              -999.000          -999.000   \n",
       "9         69.272   193.392              -999.000          -999.000   \n",
       "10        79.692    27.201              -999.000          -999.000   \n",
       "11        75.712    30.816                 2.563           252.599   \n",
       "12       103.565   106.999              -999.000          -999.000   \n",
       "13        64.128     8.232              -999.000          -999.000   \n",
       "14        14.398    17.323              -999.000          -999.000   \n",
       "15        75.271    23.067              -999.000          -999.000   \n",
       "16        67.963    47.221              -999.000          -999.000   \n",
       "17        77.267    26.967              -999.000          -999.000   \n",
       "18        68.827     5.042              -999.000          -999.000   \n",
       "19       115.058    15.337              -999.000          -999.000   \n",
       "\n",
       "    DER_prodeta_jet_jet  DER_deltar_tau_lep  ...  PRI_met_phi  PRI_met_sumet  \\\n",
       "0                 2.666               3.064  ...       -0.277        258.733   \n",
       "1              -999.000               3.473  ...       -1.916        164.546   \n",
       "2              -999.000               3.148  ...       -2.186        260.414   \n",
       "3              -999.000               3.310  ...        0.060         86.062   \n",
       "4              -999.000               3.891  ...       -0.871         53.131   \n",
       "5                -0.540               1.362  ...        2.237        282.849   \n",
       "6                 0.113               2.941  ...       -1.443        294.074   \n",
       "7              -999.000               2.897  ...       -1.761        187.299   \n",
       "8              -999.000               2.904  ...        0.024        129.804   \n",
       "9              -999.000               1.609  ...        0.845        294.741   \n",
       "10             -999.000               2.338  ...        0.688        250.178   \n",
       "11               -1.401               2.888  ...        2.148        290.547   \n",
       "12             -999.000               2.183  ...       -1.907        232.362   \n",
       "13             -999.000               2.823  ...        1.433        163.420   \n",
       "14             -999.000               0.472  ...       -1.583        198.616   \n",
       "15             -999.000               3.205  ...        2.415        122.176   \n",
       "16             -999.000               2.954  ...        2.055        191.568   \n",
       "17             -999.000               2.833  ...       -2.975        211.720   \n",
       "18             -999.000               2.116  ...       -2.033        151.816   \n",
       "19             -999.000               2.879  ...       -2.577        115.145   \n",
       "\n",
       "    PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0             2              67.435                2.150                0.444   \n",
       "1             1              46.226                0.725                1.158   \n",
       "2             1              44.251                2.053               -2.028   \n",
       "3             0            -999.000             -999.000             -999.000   \n",
       "4             0            -999.000             -999.000             -999.000   \n",
       "5             3              90.547               -2.412               -0.653   \n",
       "6             2             123.010                0.864                1.450   \n",
       "7             1              30.638               -0.715               -1.724   \n",
       "8             0            -999.000             -999.000             -999.000   \n",
       "9             1             167.735               -2.767               -2.514   \n",
       "10            0            -999.000             -999.000             -999.000   \n",
       "11            3              76.773               -0.790                0.303   \n",
       "12            1              93.117               -0.970                1.943   \n",
       "13            0            -999.000             -999.000             -999.000   \n",
       "14            0            -999.000             -999.000             -999.000   \n",
       "15            0            -999.000             -999.000             -999.000   \n",
       "16            1              36.263               -0.766               -0.686   \n",
       "17            0            -999.000             -999.000             -999.000   \n",
       "18            0            -999.000             -999.000             -999.000   \n",
       "19            0            -999.000             -999.000             -999.000   \n",
       "\n",
       "    PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                  46.062                   1.240                  -2.475   \n",
       "1                -999.000                -999.000                -999.000   \n",
       "2                -999.000                -999.000                -999.000   \n",
       "3                -999.000                -999.000                -999.000   \n",
       "4                -999.000                -999.000                -999.000   \n",
       "5                  56.165                   0.224                   3.106   \n",
       "6                  56.867                   0.131                  -2.767   \n",
       "7                -999.000                -999.000                -999.000   \n",
       "8                -999.000                -999.000                -999.000   \n",
       "9                -999.000                -999.000                -999.000   \n",
       "10               -999.000                -999.000                -999.000   \n",
       "11                 56.876                   1.773                  -2.079   \n",
       "12               -999.000                -999.000                -999.000   \n",
       "13               -999.000                -999.000                -999.000   \n",
       "14               -999.000                -999.000                -999.000   \n",
       "15               -999.000                -999.000                -999.000   \n",
       "16               -999.000                -999.000                -999.000   \n",
       "17               -999.000                -999.000                -999.000   \n",
       "18               -999.000                -999.000                -999.000   \n",
       "19               -999.000                -999.000                -999.000   \n",
       "\n",
       "    PRI_jet_all_pt  \n",
       "0          113.497  \n",
       "1           46.226  \n",
       "2           44.251  \n",
       "3            0.000  \n",
       "4            0.000  \n",
       "5          193.660  \n",
       "6          179.877  \n",
       "7           30.638  \n",
       "8            0.000  \n",
       "9          167.735  \n",
       "10           0.000  \n",
       "11         165.640  \n",
       "12          93.117  \n",
       "13           0.000  \n",
       "14           0.000  \n",
       "15           0.000  \n",
       "16          36.263  \n",
       "17           0.000  \n",
       "18           0.000  \n",
       "19           0.000  \n",
       "\n",
       "[20 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "train = pd.read_csv(DATA_TRAIN_PATH)\n",
    "test = pd.read_csv(DATA_TEST_PATH)\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 250000 samples x 30 features\n",
      "Test set size: 568238 samples x 30 features\n"
     ]
    }
   ],
   "source": [
    "print('Train set size: {} samples x {} features'.format(pd.DataFrame(tX).shape[0], pd.DataFrame(tX).shape[1]))\n",
    "print('Test set size: {} samples x {} features'.format(test.shape[0], pd.DataFrame(tX).shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 32 columns):\n",
      "Id                             250000 non-null int64\n",
      "Prediction                     250000 non-null object\n",
      "DER_mass_MMC                   250000 non-null float64\n",
      "DER_mass_transverse_met_lep    250000 non-null float64\n",
      "DER_mass_vis                   250000 non-null float64\n",
      "DER_pt_h                       250000 non-null float64\n",
      "DER_deltaeta_jet_jet           250000 non-null float64\n",
      "DER_mass_jet_jet               250000 non-null float64\n",
      "DER_prodeta_jet_jet            250000 non-null float64\n",
      "DER_deltar_tau_lep             250000 non-null float64\n",
      "DER_pt_tot                     250000 non-null float64\n",
      "DER_sum_pt                     250000 non-null float64\n",
      "DER_pt_ratio_lep_tau           250000 non-null float64\n",
      "DER_met_phi_centrality         250000 non-null float64\n",
      "DER_lep_eta_centrality         250000 non-null float64\n",
      "PRI_tau_pt                     250000 non-null float64\n",
      "PRI_tau_eta                    250000 non-null float64\n",
      "PRI_tau_phi                    250000 non-null float64\n",
      "PRI_lep_pt                     250000 non-null float64\n",
      "PRI_lep_eta                    250000 non-null float64\n",
      "PRI_lep_phi                    250000 non-null float64\n",
      "PRI_met                        250000 non-null float64\n",
      "PRI_met_phi                    250000 non-null float64\n",
      "PRI_met_sumet                  250000 non-null float64\n",
      "PRI_jet_num                    250000 non-null int64\n",
      "PRI_jet_leading_pt             250000 non-null float64\n",
      "PRI_jet_leading_eta            250000 non-null float64\n",
      "PRI_jet_leading_phi            250000 non-null float64\n",
      "PRI_jet_subleading_pt          250000 non-null float64\n",
      "PRI_jet_subleading_eta         250000 non-null float64\n",
      "PRI_jet_subleading_phi         250000 non-null float64\n",
      "PRI_jet_all_pt                 250000 non-null float64\n",
      "dtypes: float64(29), int64(2), object(1)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks clean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>224999.500000</td>\n",
       "      <td>-49.023079</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>-708.420675</td>\n",
       "      <td>-601.237051</td>\n",
       "      <td>-709.356603</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>-348.329567</td>\n",
       "      <td>-399.254314</td>\n",
       "      <td>-399.259788</td>\n",
       "      <td>-692.381204</td>\n",
       "      <td>-709.121609</td>\n",
       "      <td>-709.118631</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72168.927986</td>\n",
       "      <td>406.345647</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>454.480565</td>\n",
       "      <td>657.972302</td>\n",
       "      <td>453.019877</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>532.962789</td>\n",
       "      <td>489.338286</td>\n",
       "      <td>489.333883</td>\n",
       "      <td>479.875496</td>\n",
       "      <td>453.384624</td>\n",
       "      <td>453.389017</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>162499.750000</td>\n",
       "      <td>78.100750</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>224999.500000</td>\n",
       "      <td>105.012000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>-2.093000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>287499.250000</td>\n",
       "      <td>130.606250</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>83.446000</td>\n",
       "      <td>-4.593000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.349000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>33.703000</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>-2.275000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>349999.000000</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id   DER_mass_MMC  DER_mass_transverse_met_lep  \\\n",
       "count  250000.000000  250000.000000                250000.000000   \n",
       "mean   224999.500000     -49.023079                    49.239819   \n",
       "std     72168.927986     406.345647                    35.344886   \n",
       "min    100000.000000    -999.000000                     0.000000   \n",
       "25%    162499.750000      78.100750                    19.241000   \n",
       "50%    224999.500000     105.012000                    46.524000   \n",
       "75%    287499.250000     130.606250                    73.598000   \n",
       "max    349999.000000    1192.026000                   690.075000   \n",
       "\n",
       "        DER_mass_vis       DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000  250000.000000         250000.000000     250000.000000   \n",
       "mean       81.181982      57.895962           -708.420675       -601.237051   \n",
       "std        40.828691      63.655682            454.480565        657.972302   \n",
       "min         6.329000       0.000000           -999.000000       -999.000000   \n",
       "25%        59.388750      14.068750           -999.000000       -999.000000   \n",
       "50%        73.752000      38.467500           -999.000000       -999.000000   \n",
       "75%        92.259000      79.169000              0.490000         83.446000   \n",
       "max      1349.351000    2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot  ...  \\\n",
       "count        250000.000000       250000.000000  250000.000000  ...   \n",
       "mean           -709.356603            2.373100      18.917332  ...   \n",
       "std             453.019877            0.782911      22.273494  ...   \n",
       "min            -999.000000            0.208000       0.000000  ...   \n",
       "25%            -999.000000            1.810000       2.841000  ...   \n",
       "50%            -999.000000            2.491500      12.315500  ...   \n",
       "75%              -4.593000            2.961000      27.591000  ...   \n",
       "max              16.690000            5.684000    2834.999000  ...   \n",
       "\n",
       "         PRI_met_phi  PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000       250000.000000   \n",
       "mean       -0.010119     209.797178       0.979176         -348.329567   \n",
       "std         1.812223     126.499506       0.977426          532.962789   \n",
       "min        -3.142000      13.678000       0.000000         -999.000000   \n",
       "25%        -1.575000     123.017500       0.000000         -999.000000   \n",
       "50%        -0.024000     179.739000       1.000000           38.960000   \n",
       "75%         1.561000     263.379250       2.000000           75.349000   \n",
       "max         3.142000    2003.976000       3.000000         1120.573000   \n",
       "\n",
       "       PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
       "count        250000.000000        250000.000000          250000.000000   \n",
       "mean           -399.254314          -399.259788            -692.381204   \n",
       "std             489.338286           489.333883             479.875496   \n",
       "min            -999.000000          -999.000000            -999.000000   \n",
       "25%            -999.000000          -999.000000            -999.000000   \n",
       "50%              -1.872000            -2.093000            -999.000000   \n",
       "75%               0.433000             0.503000              33.703000   \n",
       "max               4.499000             3.141000             721.456000   \n",
       "\n",
       "       PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count           250000.000000           250000.000000   250000.000000  \n",
       "mean              -709.121609             -709.118631       73.064591  \n",
       "std                453.384624              453.389017       98.015662  \n",
       "min               -999.000000             -999.000000        0.000000  \n",
       "25%               -999.000000             -999.000000        0.000000  \n",
       "50%               -999.000000             -999.000000       40.512500  \n",
       "75%                 -2.457000               -2.275000      109.933750  \n",
       "max                  4.500000                3.142000     1633.433000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_uncomplete_features(x, threshold):\n",
    "    \"\"\"This function removes features that have a number of non-defined values above a given threshold. \n",
    "       In this dataset, the meaningless values or the ones that cannot be computed are given the values -999.0\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(y, x):\n",
    "    \"\"\"Split the dataset into subsets, each subset containing all datapoints that have the same value for \n",
    "       the categorical feature PRI_jet_num. The function returns each subset and its corresponding labels \"\"\"\n",
    "    PRI_jet_num_values = np.unique(x[:,22])\n",
    "    sub_group_indices = []\n",
    "    x_subgroup = []\n",
    "    y_subgroup = []\n",
    "    for i in range(int(np.amax(PRI_jet_num_values))+1):\n",
    "        sub_group_indices.append(np.where(x[:,22]==i))\n",
    "        x_subgroup.append(x[sub_group_indices[i],:])\n",
    "        y_subgroup.append(y[sub_group_indices[i]])\n",
    "        x_subgroup[i] = np.squeeze(x_subgroup[i])\n",
    "        x_subgroup[i] = np.delete(x_subgroup[i], 22, axis=1)\n",
    "    \n",
    "    return x_subgroup[0], y_subgroup[0], x_subgroup[1], y_subgroup[1], x_subgroup[2], y_subgroup[2], x_subgroup[3], y_subgroup[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x, mean=None, std=None):\n",
    "    ''' Standardize the data such that it has a mean of 0 and a unitary standard deviation. If mean and std are\n",
    "        provided (e.g. when we standardize the testing set based on the standardization parameters of the \n",
    "        training set), the function uses them. '''\n",
    "    \n",
    "    if mean is None:\n",
    "        mean = np.mean(x, axis=0)\n",
    "    x -= mean \n",
    "    \n",
    "    if std is None:\n",
    "        std = np.std(x, axis=0)\n",
    "    x /= std\n",
    "    \n",
    "    return x, mean, std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we'redealing with large arrays, we will use the batch iter method in order to avoid memory access problems\n",
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "    Example of use :\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, 32):\n",
    "    \"\"\"\n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "    '''Compute MSE loss.'''\n",
    "    e = y - tx.dot(w)\n",
    "    mse = (1/2) * np.mean(e**2)\n",
    "    return mse\n",
    "\n",
    "def calculate_mse(e):\n",
    "    \"\"\"Calculate the mse for vector e.\"\"\"\n",
    "    return 1/2*np.mean(e**2)\n",
    "\n",
    "\n",
    "def calculate_mae(e):\n",
    "    \"\"\"Calculate the mae for vector e.\"\"\"\n",
    "    return np.mean(np.abs(e))\n",
    "\n",
    "\n",
    "def compute_loss_ls(y, tx, w):\n",
    "    \"\"\"\n",
    "    Calculate the least-square loss using mse.\n",
    "    \"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    return calculate_mse(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_ls(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    err = y - tx.dot(w)\n",
    "    grad = -tx.T.dot(err) / len(err)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Linear regression using gradient descent.\"\"\"\n",
    "    w = initial_w\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        # gradient\n",
    "        gradient = compute_gradient_ls(y, tx, w)\n",
    "        \n",
    "        # loss\n",
    "        loss = compute_loss_ls(y, tx, w)\n",
    "        \n",
    "        # update rule\n",
    "        w -= gamma * gradient\n",
    "        \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, maxiters, gamma):\n",
    "    \"\"\"Linear regression using gradient descent (GD).\"\"\"\n",
    "    eps = 10E-5\n",
    "    assert(y.shape[0] == tx.shape[0])\n",
    "    w = initial_w\n",
    "    maxreached = False\n",
    "    N = len(y)\n",
    "    for i in range(0, maxiters+1):\n",
    "        loss = np.linalg.norm(tx @ w - y)**2 / len(y)\n",
    "        if (loss < eps):\n",
    "            break\n",
    "        grad = tx.T @ (tx @ w -  y)/N\n",
    "        w -= gamma * grad\n",
    "    if (i == maxiters):\n",
    "        print('Number of maxiterations reached.')    \n",
    "    return (w,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.64005098 -4.74073768  0.49662478 -0.64677607]\n",
      " [-0.79632198 -1.69665179 -2.95351366  1.19270966]\n",
      " [-2.00345326 -2.33172725  1.21133833  0.29142094]\n",
      " [-3.65420055  0.13578121 -3.15560134  2.85335148]\n",
      " [ 3.53975293 -0.05763163  3.46561485 -4.20354523]\n",
      " [ 0.0524609  -4.34713496 -0.71877672 -4.03469084]\n",
      " [-3.72840028  0.96745309 -2.73987999 -3.93054316]\n",
      " [-2.79693793 -1.50173715 -0.32212515 -2.98256774]\n",
      " [ 1.40406725 -0.16930164  0.0523672  -1.13107349]\n",
      " [ 2.93637454  0.80004179 -3.37701401  2.00752347]] \n",
      "\n",
      "The real coeffs are  [0.96455108 0.50000836 0.88952006 0.34161365] \n",
      "\n",
      "The found coeffs are  [0.966196   0.49574387 0.88923322 0.34396779]  and the error is  9.85864581146258e-05\n"
     ]
    }
   ],
   "source": [
    "#Test for Gradient descent\n",
    "np.random.seed(2)\n",
    "dim = 4\n",
    "test_X = 10*(np.random.rand(10,dim) -0.5)\n",
    "wtrue = np.random.rand(dim)\n",
    "print(test_X,'\\n')\n",
    "print('The real coeffs are ',wtrue,'\\n')\n",
    "test_y = test_X @ wtrue\n",
    "w0 = np.random.rand(dim)\n",
    "wfin = least_squares_GD(test_y,test_X,w0,100,0.03)\n",
    "print('The found coeffs are ',wfin[0], ' and the error is ', wfin[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.966196  , 0.49574387, 0.88923322, 0.34396779]), 9.85864581146258e-05)\n"
     ]
    }
   ],
   "source": [
    "print(wfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Linear regression using SGD.\n",
    "    Compute MSE loss\n",
    "    \"\"\"\n",
    "    w = initial_w\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size=1, num_batches=1):\n",
    "            # gradient\n",
    "            gradient = compute_gradient_ls(y_batch, tx_batch, w)\n",
    "           \n",
    "            # update rule\n",
    "            w -= gamma * gradient\n",
    "            \n",
    "            # loss\n",
    "            loss = compute_loss_ls(y_batch, tx_batch, w)\n",
    "            \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"\n",
    "    Least squares regression using normal equations.\n",
    "    Note: better use solve. Problems occur when using np.linalg.inv()\n",
    "    np.linalg.solve(a,b): solve problems of type ax=b\n",
    "    \"\"\"\n",
    "    a = tx.T.dot(tx)\n",
    "    b = tx.T.dot(y)\n",
    "    \n",
    "    w = np.linalg.solve(a, b)\n",
    "    loss = compute_loss_ls(y, tx, w)\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"Ridge regression using normal equations.\"\"\"\n",
    "    N = tx.shape[0]\n",
    "    D = tx.shape[1]\n",
    "    a = tx.T.dot(tx) + 2*N*lambda_*np.identity(D)\n",
    "    b = tx.T.dot(y)\n",
    "    \n",
    "    w = np.linalg.solve(a, b)\n",
    "    loss = compute_loss_ls(y, tx, w)\n",
    "        \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    \"\"\"apply sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_lr(y, tx, w):\n",
    "    \"\"\"\n",
    "    Compute the loss of the logistic regression\n",
    "    by negative log likelihood.\n",
    "    \"\"\"\n",
    "    prediction = sigmoid(tx.dot(w))\n",
    "    loss = y.T.dot(np.log(prediction)) + (1 - y).T.dot(np.log(1 - prediction))\n",
    "    return np.squeeze(-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_lr(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss for the logistic regression.\"\"\"\n",
    "    prediction = sigmoid(tx.dot(w))\n",
    "    gradient = tx.T.dot(prediction - y)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GD version\n",
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Logistic regression using gradient descent or SGD.\"\"\"\n",
    "    # Note: we don't have to keep track of the weithts and losses\n",
    "    w = initial_w\n",
    "    \n",
    "    # as we assume that the constant term is contained in x\n",
    "    tx = np.c_[np.ones((y.shape[0], 1)), tx]\n",
    "    \n",
    "    # gradient descent\n",
    "    for i in range(max_iters):\n",
    "        # loss\n",
    "        loss = compute_loss_lr(y, tx, w)\n",
    "\n",
    "        # gradient\n",
    "        gradient = compute_gradient_lr(y, tx, w)\n",
    "        \n",
    "        # update rule\n",
    "        w -= gamma * gradient\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD version\n",
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"Logistic regression using gradient descent or SGD.\"\"\"   \n",
    "    w = initial_w\n",
    "    \n",
    "    # as we assume that the constant term is contained in x\n",
    "    tx = np.c_[np.ones((y.shape[0], 1)), tx]\n",
    "    \n",
    "    # stochastic gradient descent\n",
    "    for i in range(max_iters):\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size=1, num_batches=1): \n",
    "            # loss\n",
    "            loss = compute_loss_lr(y_batch, tx_batch, w)\n",
    "\n",
    "            # gradient\n",
    "            gradient = compute_gradient_lr(y_batch, tx_batch, w)\n",
    "\n",
    "            # update rule\n",
    "            w -= gamma * gradient\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GD version\n",
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    \"\"\"Regularized logistic regression using gradient descent or SGD.\"\"\"\n",
    "    # same as before except that we have the additional penalty term\n",
    "    w = initial_w\n",
    "    \n",
    "    # constant term contained in x\n",
    "    tx = np.c_[np.ones((y.shape[0], 1)), tx]\n",
    "    \n",
    "    # gradient descent\n",
    "    for i in range(max_iters):\n",
    "        # loss\n",
    "        loss =  compute_loss_lr + lambda_/2 *  np.squeeze(w.T.dot(w))\n",
    "        \n",
    "        # gradient\n",
    "        gradient =  compute_gradient_lr + lambda_ * w\n",
    "        \n",
    "        # update rule\n",
    "        w -= gamma * gradient\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD version\n",
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    \"\"\"Regularized logistic regression using gradient descent or SGD.\"\"\"  \n",
    "    w = initial_w\n",
    "    \n",
    "    # constant term contained in x\n",
    "    tx = np.c_[np.ones((y.shape[0], 1)), tx]\n",
    "    \n",
    "    # gradient descent\n",
    "    for i in range(max_iters):\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size=1, num_batches=1): \n",
    "            # loss\n",
    "            loss = compute_loss_lr(y_batch, tx_batch, w) + lambda_/2 *  np.squeeze(w.T.dot(w))\n",
    "\n",
    "            # gradient\n",
    "            gradient = compute_gradient_lr(y_batch, x_batch, w) + lambda_ * w\n",
    "\n",
    "            # update rule\n",
    "            w -= gamma * gradient\n",
    "    \n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, ratio, seed=12):\n",
    "    \"\"\"Split the X and y sets into a training and a validation/testing one.\"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    permutations = np.random.permutation(len(X))\n",
    "    x = X[permutations]\n",
    "    y = y[permutations]\n",
    "    \n",
    "    idx = int(np.floor(ratio * len(X)))\n",
    "    x_train = x[:idx]\n",
    "    y_train = y[:idx]\n",
    "    x_test = x[idx:]\n",
    "    y_test = y[idx:]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    \"\"\"\n",
    "    Compute the accuracy between the real values (y) \n",
    "    and the predicted ones (y_hat).\n",
    "    Note: for binary predictions with values {0, 1} only.\n",
    "    \"\"\"\n",
    "    return np.sum(y == y_hat) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(y, X, k):\n",
    "    \"\"\"\n",
    "    k-fold cross-validation for model selection.\n",
    "    \n",
    "    y: labels\n",
    "    X: features matrix\n",
    "    k: number of folds\n",
    "    \n",
    "    output: mean accuracy and std across the k-folds\n",
    "    \"\"\"\n",
    "    \n",
    "    # Before partitionning the data we shuffle it randomly\n",
    "    permutations = np.random.permutation(len(y))\n",
    "    X = X[permutations]\n",
    "    y = y[permutations]\n",
    "    \n",
    "    # array to store the outcome accuracy  of the different folds\n",
    "    accuracies = np.zeros(k)\n",
    "    \n",
    "    # Indexes for the k different intervals\n",
    "    idxs = np.linspace(0, len(y), k+1, dtype=int) # +1 for 'upper bound'\n",
    "     \n",
    "    for i in range(k):\n",
    "        X_te = X[idxs[i]:idxs[i+1]] #test indexes\n",
    "        y_te = y[idxs[i]:idxs[i+1]]\n",
    "        \n",
    "        X_tr = np.delete(X, list(np.arange(idxs[i], idxs[i+1])), axis=0)\n",
    "        y_tr = np.delete(y, list(np.arange(idxs[i], idxs[i+1])), axis=0)\n",
    "        \n",
    "        ## TODO: implement the classifier part \n",
    "        # 1. fit data\n",
    "        # 2. compute y_hat\n",
    "        # 3. compute accuracy\n",
    "    \n",
    "    return np.mean(accuracies), np.std(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ... Mais jpeeeeense alors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template for plotting graph in 3D later.\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "x = np.linspace(-1,1,10)\n",
    "y = np.linspace(-1,1,10)\n",
    "xp,yp = np.meshgrid(x,y)\n",
    "z = xp**2 + yp**2\n",
    "surf = ax.plot_surface(xp,yp,z)\n",
    "k = np.rand()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
