{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Machine Learning project CS-433: NMR spectroscopy supervised learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedules:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Week 10 (18-24 November): \n",
    " * Tests of various linear models/simple NN on a 10% subset of data\n",
    "* Week 11 (25-1 December):\n",
    " * Feature selection: being able to come with a good set of features\n",
    "* Week 12 (2-8 December):\n",
    " * Start of big scale analysis with Spark, implementation of the models which perform well at small scale\n",
    "* Week 13 (9-15 December):\n",
    " * Wrapping up\n",
    "* Week 14 (16-22 December): \n",
    " * 19th December: Deadline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Log Book](#log)\n",
    "2. [Pipeline](#pipeline)\n",
    "3. [Data Processing](#data_proc) <br>\n",
    "&emsp;3.1. [Data Vizualisation](#data_viz) <br>\n",
    "&emsp;3.2 [Outliers detection](#outliers) <br>\n",
    "  &emsp;&emsp;3.2.1 [DBSCAN](#dbscan) <br>\n",
    "  &emsp;&emsp;3.2.2 [Inter quantile range method](#iqr) <br>\n",
    "&emsp;3.3 [Scaling](#scaling) <br>\n",
    "&emsp;&emsp;3.3.1 [Min max scaling](#minmax) <br>\n",
    "&emsp;3.4 [Dimensionality reduction](#dim_red) <br>\n",
    "  &emsp;&emsp;3.4.1 [PCA](#pca) <br>\n",
    "&emsp;3.5 [Feature Selection](#feat_sel) <br>\n",
    "  &emsp;&emsp;3.5.1 [Relative importance from linear regression](#rel_imp_lin) <br>\n",
    "  &emsp;&emsp;3.5.2 [Random forest](#rand_for) <br>\n",
    "  &emsp;&emsp;3.5.3 [Univariate feature selection](#un_feat_sel) <br>\n",
    "  &emsp;&emsp;3.5.4 [Recursive feature selection](#rec_feat_sel) <br>\n",
    "  &emsp;&emsp;3.5.5 [Lasso Regression](#lasso) <br>\n",
    "  &emsp;&emsp;3.5.6 [Boruta](#boruta) <br>\n",
    "&emsp;3.6 [Models](#models) <br>\n",
    "  &emsp;&emsp;3.6.1 [Linear Models](#lin_mods) <br>\n",
    "  &emsp;&emsp;3.6.2 [Neural Networks](#NN) <br>\n",
    "4. [Main](#main) <br>\n",
    "   4.1 [ANN implementation](#ann_imp) <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For neural net part\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Log Book\n",
    "<a id='log'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write here the log of the different techniques/improvements we add to the program: **cf log/models_log.txt** for the different models already tested and their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph ideas\n",
    "<a id='pipeline'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline graph coming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3. Data Exploration\n",
    "<a id = 'data_proc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the cells you need to load to be able to work on the rest of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if set to true, all the functions call before the main will be effective\n",
    "RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_data_X = np.load('data/CSD-10k_H_fps_1k_MD_n_12_l_9_rc_3.0_gw_0.3_rsr_1.0_rss_2.5_rse_5.npy',mmap_mode='r')\n",
    "tot_data_y = np.load('data/CSD-10k_H_chemical_shieldings.npy',mmap_mode='r')\n",
    "DATA_LEN = tot_data_X.shape[0]\n",
    "DATA_COLS = tot_data_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(n_samples,tot_data_x = tot_data_X,tot_data_y = tot_data_y):\n",
    "    #np.random.seed(14)\n",
    "    mask_data = np.random.permutation(DATA_LEN)[:n_samples]\n",
    "\n",
    "    data_X = tot_data_X[mask_data]\n",
    "    data_y = tot_data_y[mask_data]\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_train_test(n_samples,tot_data_x = tot_data_X,tot_data_y = tot_data_y):\n",
    "    data_X, data_y = load_data(n_samples,tot_data_x,tot_data_y)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(data_X,data_y,test_size = 0.2)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the number of data you want for your code either to run fast/ be precise about the dataset\n",
    "data_X,data_y = load_data(500)\n",
    "data_X_df = pd.DataFrame(data_X)\n",
    "data_y_df = pd.DataFrame(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Vizualisation\n",
    "<a id='data_viz'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribs(X,feat_indxes = None):\n",
    "    \"\"\"\n",
    "    X: pandas dataframe to plot the values for\n",
    "    feat_indxes: columns you want to plot\n",
    "    \"\"\"\n",
    "    if feat_indxes is None:\n",
    "        feat_indxes = np.random.permutation(X.shape[1])[:9]\n",
    "    else:\n",
    "        assert(feat_indxes.shape[0] == 9)\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3)\n",
    "    fig.set_size_inches(11,11)\n",
    "    for ind,i in enumerate(feat_indxes):\n",
    "        index = np.unravel_index(ind,(3,3))\n",
    "        axes[index].ticklabel_format(style='sci',scilimits=(-3,4),axis='both')\n",
    "        X.iloc[:,i].hist(ax = axes[index],bins = 80)\n",
    "        axes[index].title.set_text('col {}'.format(str(i)))\n",
    "        #data_X_df.iloc[:,i].plot.box(ax = axes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    plot_distribs(pd.DataFrame(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the different features are scaled pretty differently, we might want to scale them beforehand. Since they don' look like following a gaussian, we'll apply min/max scaling: but in order to do so, we first need to get rid of the outliers thanks to one of the following methods\n",
    "* Zscore: not adapted as our data might not be gaussian\n",
    "* DBScan:\n",
    "* Isolation Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 3.2 Outliers detection\n",
    "<a id='outliers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 DBSCAN\n",
    "<a id = 'dbscan'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: computationally too demanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Interquartile range method (IQR)\n",
    "<a id = 'iqr'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consists in considering as outliers all data points that lie in >1.5 interquartile range from the quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQR_outlier():\n",
    "    def __init__(self, l_qtile= 5, h_qtile=95):\n",
    "        self.l_qtile = l_qtile\n",
    "        self.h_qtile = h_qtile\n",
    "        \n",
    "    def _reset(self):\n",
    "        \"\"\"Reset internal data-dependent state of the scaler, if necessary.\n",
    "        __init__ parameters are not touched.\n",
    "        \"\"\"\n",
    "        if (hasattr(self,'feat_qutiles')):\n",
    "            del self.feat_qutiles\n",
    "        \n",
    "    def IQR(self,ys):\n",
    "        \"\"\"Compute the quartiles for a feature passed in argument\n",
    "        \"\"\"\n",
    "        if self.l_qtile is None or self.h_qtile is None:\n",
    "            raise ValueError(\"Quantiles not initialized\")\n",
    "            \n",
    "        q1, q3 = np.percentile(ys, [self.l_qtile,self.h_qtile])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (iqr * 1.5)\n",
    "        upper_bound = q3 + (iqr * 1.5)\n",
    "        return np.array([lower_bound,upper_bound])\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" compute the quartiles used to remove outliers later on\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape [n_samples, n_features]\n",
    "            The data used to compute the different features to erase\n",
    "        \"\"\"\n",
    "        # Reset internal state before fitting\n",
    "        self._reset()\n",
    "        self.feat_qutiles = np.array([self.IQR(feat) for feat in X.T])\n",
    "        return self\n",
    "\n",
    "            \n",
    "    def transform(self, X,y):\n",
    "        \"\"\"Perform standardization by centering and scaling\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data we want to take out the outliers of\n",
    "        \"\"\"\n",
    "        if self.feat_qutiles is None:\n",
    "            raise ValueError(\"Data not fitted yet.\")\n",
    "            \n",
    "        masks_indces = []\n",
    "        for feat,bounds in zip(X.T,self.feat_qutiles):\n",
    "            masks_indces.append(np.where((feat < bounds[0]) | (feat > bounds[1])))\n",
    "            \n",
    "        #hstack reducs everything in one dimension\n",
    "        mask_final = np.hstack(masks_indces)\n",
    "        X_trans = np.delete(X,mask_final,axis = 0)\n",
    "        y_trans = np.delete(y,mask_final,axis = 0)\n",
    "        \n",
    "        return X_trans,y_trans\n",
    "    \n",
    "    def fit_transform(self,X,y):\n",
    "        \"\"\"fit X and transform X and y accordingly\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots are meant to show whether or not a given outlier detection method is efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    data_X,data_y = load_data(3000)\n",
    "    feat_indxes = np.random.permutation(data_X.shape[1])[:9]\n",
    "    plt.figure()\n",
    "    plot_distribs(pd.DataFrame(data_X),feat_indxes)\n",
    "    plt.suptitle('Data before outliers removing', fontsize=16)\n",
    "    \n",
    "    out_det = IQR_outlier()\n",
    "    out_det.fit(data_X)\n",
    "    data_X_filt,data_y_filt = out_det.transform(data_X,data_y)\n",
    "    plt.figure()\n",
    "    plot_distribs(pd.DataFrame(data_X_filt),feat_indxes)\n",
    "    plt.suptitle('Data after outliers removed', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude from these plots that a lot of the values situated in the \"peaks\" in the center are in fact outliers according to some feature. Some of the other features could potentially be visually seem to follow a gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 3.3 Scaling\n",
    "<a id='scaling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Min/max Scaling\n",
    "<a id='minmax'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minmax scaling seems as an appropriate way to scale our data only if an outlier removing method is applied beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scaler(scaler,X_train,X_test):\n",
    "    \"\"\"\n",
    "    Function to scale outside of the pipeline\n",
    "    \"\"\"\n",
    "    X_train = minmx_scaler.fit_transform(X_train)\n",
    "    X_test = minmx_scaler.transform(X_test)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Robust Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 3.4 Dimensionality reduction\n",
    "<a id='dim_red'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 PCA\n",
    "<a id = 'pca'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that approximately 50 components are enough to explain more than 95% of the variance ==> we choose this value for most of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA(n_comp,X_train):\n",
    "    \"\"\"\n",
    "    displays the 'elbow' of the PCA, ie the screeplot\"\"\"\n",
    "    pca = PCA(n_components = n_comp)\n",
    "    pca.fit(X_train)\n",
    "    plt.figure(1)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Cumulative explained variance')\n",
    "    plt.show()\n",
    "    \n",
    "if RUN:    \n",
    "    X_train,_,_,_ = load_data_train_test(3000)\n",
    "    plot_PCA(70,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_PCA(X_train,X_test,n):\n",
    "    \"\"\"\n",
    "    Useful method to reduce train/test sets outside of the pipeline\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components = n)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 3.5 Feature Selection\n",
    "<a id='feat_sel'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Random Forest\n",
    "<a id='rand_for'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a while to run ==> pca first\n",
    "if RUN:\n",
    "    \"\"\"\n",
    "    forest = RandomForestRegressor(max_depth=4, random_state=0,n_estimators=100)\n",
    "    forest.fit(data_X, data_y)\n",
    "    w_forest = forest.feature_importances_\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 Univariate feature selection\n",
    "<a id='un_feat_sel'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "def univ_feat_sel(X,y,keep = 0.2):\n",
    "    \"\"\"\n",
    "    Plot feature selection using the f_regression from skleanr: \n",
    "    it computes an F score based on the correlation of the feature and \n",
    "    compute a pvalue based on that.\n",
    "    X: data\n",
    "    y: label\n",
    "    keep: ratio of initial features you want to keep \n",
    "    \"\"\"\n",
    "    k = int(keep * X.shape[1])\n",
    "    model = SelectKBest(score_func=f_regression, k=k)\n",
    "    fit = model.fit(X, y)\n",
    "    feature_ord_univ = np.argsort(fit.scores_)\n",
    "    plt.bar(feature_ord_univ,fit.scores_)\n",
    "if RUN:\n",
    "    data_X,data_y = load_data(1000)\n",
    "    univ_feat_sel(data_X,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the importance varies a lot among features: the method seems appropriate to do feature selection as we can see in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4 Recursive feature selection\n",
    "<a id='rec_feat_sel'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#almost impossible without a pca ==> pca first\n",
    "if RUN:\n",
    "    data_X,data_y = load_data(800)\n",
    "    data_X,_ = do_PCA(data_X,np.zeros_like(data_X),120)\n",
    "    ridge = Ridge(alpha = 0.005)\n",
    "    rfe = RFE(ridge, 3)\n",
    "    if RUN:\n",
    "        fit = rfe.fit(data_X,data_y)\n",
    "        print(\"Num Features: %d\" % fit.n_features_)\n",
    "        print(\"Selected Features: %s\" % fit.support_)\n",
    "        print(\"Feature Ranking: %s\" % fit.ranking_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it is not the first components that are the most important weirdly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.6 Boruta\n",
    "<a id='boruta'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 3.6 Models\n",
    "<a id='models'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1 Linear Models\n",
    "<a id='lin_mods'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_alphas_meth(meth,alphas,X,y,k = 4):\n",
    "    \"\"\"\n",
    "    Test the different values of alpha for a given method and return the best alpha according to the mse criterion.\n",
    "    \"\"\"\n",
    "    res_mse = []\n",
    "    for alpha in alphas: \n",
    "        rid = meth(alpha = alpha)\n",
    "        res_mse.append(-cross_val_score(rid,X,y,cv = k,scoring='neg_mean_squared_error').mean())\n",
    "    plt.semilogx(alphas,res_mse)\n",
    "    plt.ylabel('Mse')\n",
    "    plt.xlabel('lambdas')\n",
    "    return alphas[np.argmin(res_mse)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6.1.1 Lasso Regression\n",
    "<a id='lasso'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso: with pca40:      0.01\n",
    "#lasso: no pca    :      0.007\n",
    "if RUN:\n",
    "    data_X,data_y = load_data(3000)\n",
    "    \n",
    "    out = IQR_outlier()\n",
    "    min_max = MinMaxScaler()\n",
    "    pca = PCA(n_components=80)\n",
    "    data_X,data_y = out.fit_transform(data_X,data_y)\n",
    "    pipeline = Pipeline([('min_max', min_max), ('pca', pca)])\n",
    "    data_X = pipeline.fit_transform(data_X)\n",
    "    \n",
    "    interv = np.logspace(np.log10(0.001),np.log10(10000),25)\n",
    "    alph_opt = test_alphas_meth(ElasticNet,interv,data_X,data_y)\n",
    "    print(alph_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6.1.2 Ridge Regression\n",
    "<a id='lasso'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    \n",
    "    #ridge: with pca40:      0.006\n",
    "    #ridge: no pca    :      0.002\n",
    "    data_X,data_y = load_data(3000)\n",
    "    \n",
    "    out = IQR_outlier()\n",
    "    min_max = MinMaxScaler()\n",
    "    pca = PCA(n_components=80)\n",
    "    data_X,data_y = out.fit_transform(data_X,data_y)\n",
    "    pipeline = Pipeline([('min_max', min_max), ('pca', pca)])\n",
    "    data_X = pipeline.fit_transform(data_X)\n",
    "    \n",
    "    interv = np.logspace(np.log10(0.001),np.log10(10000),25)\n",
    "    alph_opt = test_alphas_meth(Ridge,interv,data_X,data_y)\n",
    "    print(alph_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6.1.3 Elastic Net\n",
    "<a id='lasso'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticnet: with pca40:      0.006\n",
    "#elasticnet: no pca    :      0.002\n",
    "if RUN:\n",
    "    data_X,data_y = load_data(3000)\n",
    "    \n",
    "    out = IQR_outlier()\n",
    "    min_max = MinMaxScaler()\n",
    "    pca = PCA(n_components=80)\n",
    "    data_X,data_y = out.fit_transform(data_X,data_y)\n",
    "    pipeline = Pipeline([('min_max', min_max), ('pca', pca)])\n",
    "    data_X = pipeline.fit_transform(data_X)\n",
    "    \n",
    "    interv = np.logspace(np.log10(0.001),np.log10(10000),25)\n",
    "    alph_opt = test_alphas_meth(ElasticNet,interv,data_X,data_y)\n",
    "    print(alph_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Neural Nets\n",
    "\n",
    "<a id='NN'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n,100)\n",
    "        #self.fc2 = nn.Linear(80,50)\n",
    "        #self.fc3 = nn.Linear(624,624)\n",
    "        self.fc4 = nn.Linear(100,1)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, monitor_loss=False):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3) \n",
    "    nb_epochs = 100\n",
    "    \n",
    "    # Monitor loss\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            sum_loss += loss.item() # compute loss for each mini batch for 1 epoch\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        # Monitor loss\n",
    "        losses.append(sum_loss)\n",
    "        \n",
    "        print('[epoch {:d}] loss: {:0.2f}'.format(e+1, sum_loss))\n",
    "    \n",
    "    if monitor_loss:\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(model, data_input):\n",
    "    y_hat = model(data_input)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(y_actual, y_pred):\n",
    "    mse = mean_squared_error(y_actual, y_pred)\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    print(\"Obtained MSE on test set %2.2f \" % mse)\n",
    "    print(\"Obtained MAE on test set %2.2f \" % mae)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 4. Main\n",
    "<a id='main'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_score(cv_results):\n",
    "    \"\"\"\n",
    "    cv_results:dictionarry having\n",
    "    test_neg_mean_squared_error,test_neg_mean_absolute_error and test_r2 as its key\n",
    "    \"\"\"\n",
    "    K = len(cv_results['test_neg_mean_squared_error'])\n",
    "    mse = -cv_results['test_neg_mean_squared_error'].mean()\n",
    "    mae = -cv_results['test_neg_mean_absolute_error'].mean()\n",
    "    r2 = cv_results['test_r2'].mean()\n",
    "    print(\"On %i folds\" % K)\n",
    "    print(\"Obtained MSE on test set %2.2f \" % mse)\n",
    "    print(\"Obtained MAE on test set %2.2f \" % mae)\n",
    "    print(\"Obtained r2 on test set %2.2f \" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model(results,pipeline):\n",
    "    \"\"\"\n",
    "    Write a log file of the model in order to keep trace of it\n",
    "    \"\"\"\n",
    "    date = (datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    mse = -results['test_neg_mean_squared_error'].mean()\n",
    "    mae = -results['test_neg_mean_absolute_error'].mean()\n",
    "    r2 = results['test_r2'].mean()\n",
    "    file_name = 'mae=%.2f_mse=%.2f_R2%.2f='%(mae,mse,r2) + date + '.txt'\n",
    "    file_path = './log'\n",
    "    \n",
    "    res = {'mae':mae,'mse':mse,'r2':r2}\n",
    "    \n",
    "    pipeline = [str(i) for i in list(pipeline)]\n",
    "\n",
    "    def defo(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        raise TypeError('Not serializable')\n",
    "    with open('./log/' + file_name, 'w',encoding=\"utf-8\",newline='\\r\\n') as file:\n",
    "        json.dump(res,file,indent=4,ensure_ascii=False)\n",
    "        json.dump(pipeline,file,default=defo)\n",
    "    print('Log saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING = ['neg_mean_squared_error', 'neg_mean_absolute_error','r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell here is meant to do a whole pipeline, from loading a certain number of samples, preprocessing etc. We keep using the R2 score, the MSE and the MAE as our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline 1\n",
    "data_X,data_y = load_data(10000)\n",
    "\n",
    "out = IQR_outlier()\n",
    "data_X,data_y = out.fit_transform(data_X,data_y)\n",
    "\n",
    "pca = PCA()\n",
    "min_max = MinMaxScaler()\n",
    "rid = Ridge()\n",
    "sel = SelectKBest(score_func=f_regression)\n",
    "pipeline = Pipeline([\n",
    "  ('min_max',min_max),\n",
    "  ('feat_sel', sel),\n",
    "  ('pca',pca),\n",
    "  ('rid', rid)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [90,100,110],\n",
    "    'rid__alpha': np.logspace(np.log10(0.1),np.log10(100),5),\n",
    "    'feat_sel__k': [5000,6000],\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "search = GridSearchCV(pipeline, param_grid, scoring = 'neg_mean_absolute_error',iid=False, cv=cv)\n",
    "search.fit(data_X,data_y)\n",
    "\n",
    "best_score = search.best_score_\n",
    "bp_ = search.best_params_\n",
    "be_ = search.best_estimator_\n",
    "\n",
    "#pipeline.set_params(pca__n_components= bp_['pca__n_components'],feat_sel__estimator__alpha = bp_['feat_sel__estimator__alpha'])\n",
    "pipeline.set_params(pca__n_components= bp_['pca__n_components'],feat_sel__k = bp_['feat_sel__k'],rid__alpha = bp_['rid__alpha'])\n",
    "\n",
    "results = cross_validate(pipeline,data_X, data_y, cv = cv,scoring=SCORING)\n",
    "log_model(results,pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_score(results)\n",
    "print(search.best_estimator_.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Pipeline 2\n",
    "\n",
    "data_X,data_y = load_data(10000)\n",
    "\n",
    "out = IQR_outlier()\n",
    "data_X,data_y = out.fit_transform(data_X,data_y)\n",
    "\n",
    "pca = PCA()\n",
    "rob = RobustScaler()\n",
    "rid = Ridge()\n",
    "pipeline = Pipeline([\n",
    "  ('rob',rob),\n",
    "  ('pca',pca),\n",
    "  ('rid', rid)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [60, 80, 100],\n",
    "    'rid__alpha': np.logspace(np.log10(0.001),np.log10(1000),10)\n",
    "   # 'feat_sel__estimator__alpha': np.logspace(np.log10(0.001),np.log10(1000), 5),\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "search = GridSearchCV(pipeline, param_grid, scoring = 'neg_mean_absolute_error',iid=False, cv=cv)\n",
    "search.fit(data_X,data_y)\n",
    "\n",
    "best_score = search.best_score_\n",
    "bp_ = search.best_params_\n",
    "be_ = search.best_estimator_\n",
    "\n",
    "#pipeline.set_params(pca__n_components= bp_['pca__n_components'],feat_sel__estimator__alpha = bp_['feat_sel__estimator__alpha'])\n",
    "pipeline.set_params(pca__n_components= bp_['pca__n_components'],rid__alpha = bp_['rid__alpha'])\n",
    "\n",
    "results = cross_validate(pipeline,data_X, data_y, cv = cv,scoring=SCORING)\n",
    "log_model(results,pipeline)\n",
    "display_score(results)\n",
    "print(search.best_estimator_.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline 3\n",
    "data_X,data_y = load_data(5000)\n",
    "\n",
    "out = IQR_outlier()\n",
    "data_X,data_y = out.fit_transform(data_X,data_y)\n",
    "\n",
    "pca = KernelPCA(kernel = 'rbf',degree = 3)\n",
    "min_max = MinMaxScaler()\n",
    "rid = Ridge()\n",
    "pipeline = Pipeline([\n",
    "  ('min_max',min_max),\n",
    "  ('pca',pca),\n",
    "  ('ridge', rid)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [80, 100],\n",
    "    'ridge__alpha': [10,30,50,100],\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "search = GridSearchCV(pipeline, param_grid, scoring = 'neg_mean_absolute_error',iid=False, cv=cv)\n",
    "search.fit(data_X,data_y)\n",
    "\n",
    "best_score = search.best_score_\n",
    "bp_ = search.best_params_\n",
    "be_ = search.best_estimator_\n",
    "\n",
    "#pipeline.set_params(pca__n_components= bp_['pca__n_components'],feat_sel__estimator__alpha = bp_['feat_sel__estimator__alpha'])\n",
    "pipeline.set_params(pca__n_components= bp_['pca__n_components'],ridge__alpha = bp_['ridge__alpha'])\n",
    "\n",
    "results = cross_validate(pipeline,data_X, data_y, cv = cv,scoring=SCORING)\n",
    "log_model(results,pipeline)\n",
    "display_score(results)\n",
    "print(search.best_estimator_.named_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 ANN implementation\n",
    "<a id='ann_imp'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural nets\n",
    "#Get the data\n",
    "X_train,X_test,y_train,y_test = load_data_train_test(10000)\n",
    "X_train, X_test = do_PCA(X_train,X_test,40)\n",
    "minmx_scaler = MinMaxScaler()\n",
    "X_train, X_test = apply_scaler(minmx_scaler,X_train,X_test)\n",
    "\n",
    "#Convert to tensors\n",
    "train_input = torch.Tensor(X_train)\n",
    "test_input = torch.Tensor(X_test)\n",
    "train_target = torch.Tensor(y_train.reshape(len(y_train), 1))\n",
    "test_target = torch.Tensor(y_test.reshape(len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(train_input.shape)\n",
    "print(train_target.shape)\n",
    "print(test_input.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Train model\n",
    "mini_batch_size = 10\n",
    "model = Net(40)\n",
    "losses = train_model(model, train_input, train_target, mini_batch_size, monitor_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_hat = make_pred(model, test_input)\n",
    "\n",
    "#Compute score\n",
    "mse_nn, mae_nn = compute_score(y_test, y_hat.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(100)+1, losses)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Loss evolution during training', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(40)+1, rf.feature_importances_)\n",
    "plt.xlabel('Feature number')\n",
    "plt.ylabel('')\n",
    "plt.title('Feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# architecture 1\n",
    "mlp_1 = Sequential()\n",
    "\n",
    "mlp_1.add(Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "mlp_1.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "mlp_1.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "mlp_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture 2\n",
    "mlp_2 = Sequential()\n",
    "\n",
    "# The Input Layer\n",
    "mlp_2.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers\n",
    "mlp_2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "mlp_2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "mlp_2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer\n",
    "mlp_2.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network\n",
    "mlp_2.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "mlp_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "#checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ann_model = mlp_2\n",
    "ann_model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split = 0.2) #callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model\n",
    "y_hat = ann_model.predict(X_test)\n",
    "\n",
    "#Compute score\n",
    "mse_nn, mae_nn = compute_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
